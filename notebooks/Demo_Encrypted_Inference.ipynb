{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPCM-X: Encrypted Inference Demo\n",
    "\n",
    "This notebook demonstrates the complete pipeline for privacy-preserving CNN inference using homomorphic encryption.\n",
    "\n",
    "**Based on:** \"Enhancing Privacy in Deep Neural Networks: Techniques and Applications\" (Raj et al., IEEE INDIACOM 2025)\n",
    "\n",
    "**Novel Extension:** Adaptive Polynomial Activations (APA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PPCM-X modules\n",
    "from src.data_loader import get_data_loaders, get_sample_batch, get_dataset_info\n",
    "from src.model_plain import get_model, count_parameters, PPCM_CNN, PPCM_X_CNN\n",
    "from src.activations_poly import PolyReLU, AdaptivePolyActivation, PolynomialCoefficients\n",
    "from src.he_utils import HEContext, benchmark_he_operations\n",
    "from src.model_encrypted import EncryptedPPCM, HybridEncryptedModel\n",
    "\n",
    "print(\"PPCM-X modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Polynomial Activation Approximations\n",
    "\n",
    "Visualize how polynomial functions approximate ReLU for HE compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare polynomial approximations to true ReLU\n",
    "x = torch.linspace(-3, 3, 200)\n",
    "true_relu = torch.relu(x)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i, degree in enumerate([2, 3, 4]):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    poly_relu = PolyReLU(degree=degree)\n",
    "    approx = poly_relu(x)\n",
    "    \n",
    "    plt.plot(x.numpy(), true_relu.numpy(), 'b-', label='True ReLU', linewidth=2)\n",
    "    plt.plot(x.numpy(), approx.detach().numpy(), 'r--', label=f'Poly (deg={degree})', linewidth=2)\n",
    "    \n",
    "    mse = poly_relu.approximation_error(x).item()\n",
    "    plt.title(f'Degree {degree} (MSE: {mse:.4f})')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(-1, 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../experiments/metrics_plots/polynomial_approximations.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Architecture Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model architectures\n",
    "models = {\n",
    "    'PPCM (Base)': get_model('ppcm', 'mnist'),\n",
    "    'PPCM-X (Fixed Poly)': get_model('ppcm_x', 'mnist', adaptive_activation=False, poly_degree=3),\n",
    "    'PPCM-X (Adaptive)': get_model('ppcm_x', 'mnist', adaptive_activation=True),\n",
    "}\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(\"=\"*50)\n",
    "for name, model in models.items():\n",
    "    params = count_parameters(model)\n",
    "    print(f\"{name}: {params:,} parameters\")\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "for name, model in models.items():\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "    print(f\"{name} output shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adaptive Activation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze adaptive activation behavior\n",
    "model = get_model('ppcm_x', 'mnist', adaptive_activation=True)\n",
    "\n",
    "# Get sample data\n",
    "train_loader, _, _ = get_data_loaders('mnist', batch_size=32)\n",
    "x_batch, _ = next(iter(train_loader))\n",
    "\n",
    "# Get activation statistics\n",
    "stats = model.get_activation_stats(x_batch)\n",
    "print(\"Adaptive Activation Degrees Selected:\")\n",
    "for layer, degree in stats.items():\n",
    "    print(f\"  {layer}: degree {degree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HE Context and Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark HE operations\n",
    "presets = ['fast', 'balanced', 'accurate']\n",
    "benchmark_results = {}\n",
    "\n",
    "for preset in presets:\n",
    "    print(f\"\\nBenchmarking {preset} preset...\")\n",
    "    context = HEContext(preset=preset)\n",
    "    results = benchmark_he_operations(context, vector_size=784, num_iterations=5)\n",
    "    benchmark_results[preset] = results\n",
    "    \n",
    "    print(f\"  Encrypt: {results['encrypt_ms']:.2f} ms\")\n",
    "    print(f\"  Decrypt: {results['decrypt_ms']:.2f} ms\")\n",
    "    print(f\"  Add: {results['add_ms']:.2f} ms\")\n",
    "    print(f\"  Multiply: {results['mul_ms']:.2f} ms\")\n",
    "    print(f\"  Poly Eval: {results['poly_eval_ms']:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize benchmark results\n",
    "operations = ['encrypt_ms', 'decrypt_ms', 'add_ms', 'mul_ms', 'poly_eval_ms']\n",
    "op_labels = ['Encrypt', 'Decrypt', 'Add', 'Multiply', 'Poly Eval']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(operations))\n",
    "width = 0.25\n",
    "\n",
    "for i, preset in enumerate(presets):\n",
    "    values = [benchmark_results[preset][op] for op in operations]\n",
    "    ax.bar(x + i*width, values, width, label=preset.capitalize())\n",
    "\n",
    "ax.set_ylabel('Time (ms)')\n",
    "ax.set_title('HE Operation Benchmarks by Preset')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(op_labels)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../experiments/metrics_plots/he_benchmarks.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encrypted Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test encrypted model\n",
    "model = get_model('ppcm_x', 'mnist', adaptive_activation=True)\n",
    "encrypted_model = EncryptedPPCM(model, he_preset='fast')\n",
    "\n",
    "# Get test sample\n",
    "x, y = get_sample_batch('mnist', batch_size=1)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"True label: {y.item()}\")\n",
    "\n",
    "# Run encrypted inference\n",
    "import time\n",
    "start = time.time()\n",
    "enc_output = encrypted_model(x)\n",
    "inference_time = time.time() - start\n",
    "\n",
    "prediction = enc_output.argmax(dim=-1).item()\n",
    "print(f\"\\nEncrypted prediction: {prediction}\")\n",
    "print(f\"Inference time: {inference_time*1000:.2f} ms\")\n",
    "\n",
    "# Show timing breakdown\n",
    "timing = encrypted_model.get_timing_breakdown()\n",
    "print(\"\\nLayer timing breakdown:\")\n",
    "for layer, t in timing.items():\n",
    "    print(f\"  {layer}: {t*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plaintext vs Encrypted Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare plaintext and encrypted outputs\n",
    "hybrid = HybridEncryptedModel(model)\n",
    "\n",
    "# Test on multiple samples\n",
    "_, _, test_loader = get_data_loaders('mnist', batch_size=1)\n",
    "\n",
    "comparisons = []\n",
    "for i, (x, y) in enumerate(test_loader):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    \n",
    "    result = hybrid.compare_outputs(x)\n",
    "    comparisons.append({\n",
    "        'label': y.item(),\n",
    "        'plain_pred': result['plain_pred'][0],\n",
    "        'enc_pred': result['encrypted_pred'][0],\n",
    "        'mse': result['mse'],\n",
    "        'match': result['predictions_match']\n",
    "    })\n",
    "\n",
    "# Summary\n",
    "match_rate = sum(c['match'] for c in comparisons) / len(comparisons)\n",
    "avg_mse = np.mean([c['mse'] for c in comparisons])\n",
    "\n",
    "print(f\"Prediction match rate: {match_rate*100:.1f}%\")\n",
    "print(f\"Average output MSE: {avg_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE distribution\n",
    "mse_values = [c['mse'] for c in comparisons]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(mse_values, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Output MSE (Plaintext vs Encrypted)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Output Differences')\n",
    "plt.axvline(np.mean(mse_values), color='r', linestyle='--', label=f'Mean: {np.mean(mse_values):.6f}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../experiments/metrics_plots/mse_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "\n",
    "for i, (x, y) in enumerate(test_loader):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    \n",
    "    ax = axes[i // 5, i % 5]\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        plain_pred = model(x).argmax().item()\n",
    "    enc_pred = encrypted_model(x).argmax().item()\n",
    "    \n",
    "    # Plot\n",
    "    ax.imshow(x.squeeze().numpy(), cmap='gray')\n",
    "    ax.set_title(f'True: {y.item()}\\nPlain: {plain_pred}, Enc: {enc_pred}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../experiments/metrics_plots/sample_predictions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This demo showed:\n",
    "1. Polynomial activation approximations for HE compatibility\n",
    "2. PPCM-X model with adaptive activations\n",
    "3. HE operation benchmarks across different parameter presets\n",
    "4. Encrypted inference pipeline\n",
    "5. Comparison between plaintext and encrypted outputs\n",
    "\n",
    "The PPCM-X framework enables privacy-preserving inference with minimal accuracy loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
